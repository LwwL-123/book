# 分页方案

后端开发中为了防⽌⼀次性加载太多数据导致内存、磁盘IO都开销过⼤，经常需要分页展⽰，这个时候就需要⽤到MySQL的LIMIT关键字。但你以为LIMIT分页就万事⼤吉了么，Too young,too simple啊，LIMIT在数据量⼤的时候极可能造成的⼀个问题就是深度分页。



## 1. 案例

```sql
CREATE TABLE `cps_user_order_detail` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `user_id` varchar(32) NOT NULL DEFAULT '' COMMENT '⽤户ID',
  `order_id` bigint(20) DEFAULT NULL COMMENT '订单id',
  `sku_id` bigint(20) unsigned NOT NULL COMMENT '商品ID',
  `order_time` datetime DEFAULT NULL COMMENT '下单时间,格式yyyy-MM-dd HH:mm:ss',
   PRIMARY KEY (`id`),
   KEY `idx_time_user` (`order_time`,`user_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT='⽤户订单详情
```



然后⼿动向表⾥插⼊120W条数据。
现在有个需求：分页展⽰⽤户的订单详情，按照下单时间倒序。
表结构精简了，需求也简单。于是哗哗哗的写完代码，提测上线了。早期运⾏⼀切正常，可随着订单量的不断增⼤，发现系统越发的缓慢，还时不时报出⼏个慢查询。这个时候你就该想到是LIMIT偏移的问题了，没错，不是你的SQL不够优美，就是MySQL⾃⾝的机制。



这里我就简单以两条SQL为例，如下图，分别是从100和100W的位置偏移分页，可以看到时间相差很大。这还不算其它数据运算和处理的时间，单一条SQL的查询就耗时一秒以上，在对用户提供的功能里这是不能容忍的（电商里经常要求一个接口的RT不超过200ms）。

![img](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620164930.png)



这里我们再看下执行计划，如下图所示：

![img](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620164935.png)



在此先介绍一下执行计划Extra列可能出现的值及含义：

1. Using where：表示优化器需要通过索引回表查询数据。
2. Using index：即覆盖索引，表示直接访问索引就足够获取到所需要的数据，不需要通过索引回表，通常是通过将待查询字段建立联合索引实现。
3. Using index condition：在5.6版本后加入的新特性，即大名鼎鼎的索引下推，是MySQL关于减少回表次数的重大优化。
4. Using filesort:文件排序，这个一般在ORDER BY时候，数据量过大，MySQL会将所有数据召回内存中排序，比较消耗资源。



再看看上图，同样的语句，只以为偏移量不同，就造成了执行计划的千差万别。第一条语句LIMIT 100,6type列的值是range，表示范围扫描，性能比ref差一个级别，但是也算走了索引，并且还应用了索引下推：就是说在WHERE之后的下单时间删选走了索引，并且之后的ORDER BY也是根据索引下推优化，在执行WHERE条件筛选时同步进行的（没有回表）。
而第二条语句LIMIT 1000000,6压根就没走索引，type列的值是ALL，显然是全表扫描。并且Extra列字段里的Using where表示发生了回表，Using filesort表示ORDER BY时发生了文件排序。所以这里慢在了两点：一是文件排序耗时过大，二是根据条件筛选了相关的数据之后，需要根据偏移量回表获取全部值。无论是上面的哪一点，都是LIMIT偏移量过大导致的，所以实际开发环境经常遇到非统计表量级不得超过一百万的要求。



**优化**

原因分析完了，那么LIMIT深度分页在实际开发中怎么优化呢？

- 通过主键索引优化。什么意思呢？就是把上面的语句修改成：

```sql
SELECT * FROM cps_user_order_detail d WHERE d.id > #{maxId} AND d.order_time>'2020-8-5 00:00:00' ORDER BY d.order_time LIMIT 6;
```

如上代码所示，同样也是分页，但是有个maxId的限制条件，这个是什么意思呢，maxId就是上一页中的最大主键Id。所以采用此方式的前提：

1. 主键必须自增不能是UUID并且前端除了传基本分页参数pageNo,pageSize外，还必须把每次上一页的最大Id带过来，

2. 该方式不支持随机跳页，也就是说只能上下翻页。如下图所示是某知名电商中的实际页面。



- 通过Elastic Search搜索引擎（基于倒排索引），实际上类似于淘宝这样的电商基本上都是把所有商品放进ES搜索引擎里的（那么海量的数据，放进MySQL是不可能的，放进Redis也不现实）。但即使用了ES搜索引擎，也还是有可能发生深度分页的问题的，这时怎么办呢？答案是通过游标scroll



## 2. 常见的分页

### 2.1 Offset 分页

一种常见的方法是偏移分页。客户端使用参数limit和offset对元素进行分页。

```
GET /elements?limit=100 => 客户端收到前100个元素。
GET /elements?limit=100&offset=100 => 客户端收到下100个元素。
GET /elements?limit=100&offset=200 => 客户端只收到50个元素。所以就结束了。
```

有些API使用参数pageNumber和pageSize，而不是limit和offset。但这基本上是一种方法。

缺点是：

- 速度慢。这里的一个问题是服务器的数据库查询中使用的OFFSET子句。当涉及到有数百万条目的表时，它的速度慢得令人难以置信。没有涉及索引，可能会加快我们的查询速度。
- 不安全。如果在两个请求期间元素顺序发生变化，真的很容易错过元素。如果前一个请求的一个元素被删除了，下面一个页面的一个元素就会上移到一个已经交付的页面。

题外话：通常情况下，服务器会发送响应中所有元素的总量（总数或计数）。这可能看起来很方便。但实际上，这对性能有影响，因为必须针对数据库执行一个额外的昂贵的COUNT。但最重要的是，大多数客户无论如何都不需要这些信息。他们只对下一个页面感兴趣（也许还有上一个）。很少需要随机访问页面（例如，"给我230页中的24页"）。在这种情况下，客户端需要知道元素的总量来计算可能的页面数量。



### 2.2 Keyset 分页

一个更好的方法是利用一个索引列（通常是一个时间戳列，如date_created或date_modified）。客户端使用最后一个页面中最后一个元素的时间戳作为下一个请求的参数。

```
GET /elements?pageSize=100                
  => 客户端收到最开始的100个元素。页面的最后一个元素的`date_modified`字段为1504224000 (=2017年9月1日12:00:00 AM)

GET /elements?pageSize=100&modifiedSince=1504224000
  => 客户端收到1504224000以来的100个元素。页面的最后一个元素是在1506816000修改的。以此类推。
```

这种方法很容易实现，速度快，对许多用例来说应该是足够好的。但仍有一些缺点。

- 无休止的循环。如果一个页面的所有元素都有相同的时间戳，我们就会陷入无休止的循环。在实践中，这很容易发生在许多元素的批量更新之后。在这里，我们唯一能做的就是通过以下方式使无休止的循环不那么容易发生。
  - 始终使用较高的页面大小。
  - 使用精度为毫秒的时间戳（我们不能想当然地认为这一点。例如，在MySQL 5.6.4之前，只有精度为秒的时间戳列）。
- 效率不高。当许多元素具有相同的时间戳并且它们重叠在两个页面上时，客户端可能会多次接收和处理相同的元素。

幸运的是，我们可以通过给密钥/时间戳添加更多的信息来改善密钥集的分页。一个例子是Timestamp_Offset_Checksum标记。



### 2.3 Timestamp_ID分页

该令token的格式为Timestamp_ID，只包含两个部分。

- 时间戳。当前页面的最后一个元素的时间戳。它通常被映射到一个列，如modificationDate或creationDate。
- ID：当前页面最后一个元素的ID（主键）。这是必要的，以区分具有相同时间戳的元素。

这个实现可以归结为一个简单而智能的SQL WHERE子句

```sql
-- 假设T是时间戳，I是token中包含的id。
SELECT * FROM elementTable
WHERE (
  timestampColumn > T 
  OR (timestampColumn = T AND idColumn > I)
)
AND timestampColumn < now()
ORDER BY timestampColumn asc, idColumn asc;
-- idColumn中的id必须是唯一的(对于主键来说是开箱即用的)
-- timestampColumn和idColumn都需要索引
```

除了这个查询之外，不需要应用花哨的算法。让我们考虑一些案例来看看这种方法的实际应用。

![All elements have different timestamps.](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620164945.svg)

如果所有元素都有不同的时间戳，并且token为30_3，那么搜索所有具有时间戳> 30的元素将终止它。我们正确地继续第4元素。



![Multiple elements with the same timestamp 20 are overlapping two pages.](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620164951.svg)

对于具有相同时间戳20的多个元素，我们需要令牌的ID部分。否则，我们将错过所有带有时间戳20的元素(如果我们只查询时间戳> 20)。但是添加子句timestamp = 20 AND id > 3将在下一页中包含元素4和5。



![All elements have the same timestamp](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620164955.svg)

如果所有元素都具有相同的时间戳(比如10)，那么第二个子句就更加相关了。没有漏掉任何元素。

注意，这种方法可以轻松地处理大量具有相同时间戳的元素。我们不会陷入无尽的循环(与简单的Timestamp方法相反)，并由于有恒定的LIMIT(与Timestamp Offset Checksum方法相反)而保持恒定的性能。



<img src="https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620165000.svg" alt="An element is changed between two page requests." style="zoom:50%;" />

让我们假设一个元素的时间戳(比如最后一次修改的日期)在两次页面请求期间被更新(即设置为一个更高的值)。看看时间戳为20的元素3。它的时间戳在第1页交付后设置为99。所以它移到了元素序列的最后。因此，它被两次交付给客户端——甚至多次。必须由客户来处理。但这里最重要的一点是，我们不会错过任何元素(比如元素4)。



> 什么是`AND timestampColumn < now()`

我们还没有提到附加条件AND timestampColumn < now()。为了说明它的相关性，让我们假设它不存在。然后，假设以下操作在相同的时间戳内发生(例如，99)

- 更新元素3的时间戳(到99)请求并交付最后一个页面。
- 元素3是这个页面的最后一个元素。token是99_3。
- 现在元素2(注意2 < 3!)被更新(当前时间戳仍然是99。这就是新的时间戳)。

![Missed elements at the last page if we would deliver elements with the current timestamp.](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620165004.svg)

在这种情况下，下一个令牌为99_3的请求不会返回元素2。因此，当请求最后一页而更改发生在完全相同的时间戳时，我们可能会错过一些元素。这是可能的吗?这取决于时间戳的精确度。强烈建议使用毫秒精度，这使得这些情况不太可能(但也不是不可能)。但是，当涉及到遗留应用程序和模式时，我们可能会面临第二种精度。我们可能会错过元素。

不考虑精度，我们可以通过向SQL查询添加AND timestampColumn < now()来解决这个问题。这样，我们就不再交付元素3了(因为now()返回99)。因此延续令牌变为20_2(而不是99_3)。因此，下一个请求(通常在下一次分页运行中)将正确地返回已更新的元素2和3。



一些最后的想法和影响。

- 我们的客户端滞后于现实1毫秒或1秒。我们可能不得不做更多的请求来获取相同数量的元素（这在很大程度上取决于时间戳的精度和请求频率）。决定这对你的系统是否真的是一个问题。
- 同样，使用精度为毫秒的时间戳。如果你面对的是秒级精度的列，考虑进行模式迁移（如果可能的话）。例如，MySQL 5.6.4最终支持它们。
- 实施。注意，在我们的应用程序和数据库中，now()可能有轻微的差异。时间戳可能不同。这要么会增加滞后性，要么会使整个修复失效。不同的时间戳不应该发生，但现实告诉我们其他的故事。带走。如果我们在应用程序中生成now()的值（例如通过Instant.now()或new Date()），我们也必须在应用层中生成用于更新和插入的时间戳。不要让数据库来做（例如通过数据库函数如now()或current_timestamp()）。



#### 约束

- 在ID和时间戳列上都必须有一个索引。
- 这些ID必须是唯一的。
- 在每个查询中，我们必须在时间戳和ID之后排序。这样，即使在时间戳相同的情况下，我们也能得到一个不变的顺序。
- 在一次分页运行中，我们可能会多次交付一个元素（在时间戳变化和移动元素的情况下）。客户端必须适应这种情况；他必须是临时性的。
  根据时间戳的精度，客户端会落后于现实的1毫秒或1秒。



# 总结

**传统分页的特点：**

- 可以直接根据页码跳转到特定页
- 可能会出现重复、丢失数据的情况
- 页数较大时性能会降低
- 排序条件与分页无关

**游标分页的特点：**

- 不可以直接跳转到特定页（知道页数），但是可以直接跳转到最后一页，能加载下一页，上一页。
- 不会出现重复、丢失数据的情况
- 查询效率与页数无关，并且优于传统分页
- 不适合排序条件比较复杂的分页







# 补充: 一道面试题

> ***面试题：***在数据量很大的情况下，怎么实现深度分页？

大家在面试时，或者准备面试中可能会遇到上述的问题，大多的回答基本上是`分库分表建索引`，这是一种很`标准的正确回答`，但现实总是很骨感，所以面试官一般会追问你一句，现在工期不足，人员不足，该怎么实现深度分页？



## 惨痛的教训

***首先必须明确一点：***深度分页可以做，但是深度随机跳页绝对需要禁止。

上一张图：

![img](https://picture-1258612855.cos.ap-shanghai.myqcloud.com/20220620165011.png)

你们猜，我点一下第`142360`页，服务会不会爆炸？

像`MySQL`，`MongoDB`数据库还好，本身就是专业的数据库，处理的不好，最多就是慢，但如果涉及到`ES`，性质就不一样了，我们不得不利用 `SearchAfter` Api，去循环获取数据，这就牵扯到内存占用的问题，如果当时代码写的不优雅，直接就可能导致内存溢出。

## 为什么不能允许随机深度跳页

从技术的角度浅显的聊一聊为什么不能允许随机深度跳页，或者说为什么不建议深度分页

### MySQL

分页的基本原理：

```sql
SELECT * FROM test ORDER BY id DESC LIMIT 10000, 20;
```

LIMIT 10000 , 20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行。如果是LIMIT 1000000 , 100，需要扫描1000100 行，在一个高并发的应用里，每次查询需要扫描超过100W行，不炸才怪。

### MongoDB

分页的基本原理：

```sql
db.t_data.find().limit(5).skip(5);
```

同样的，随着页码的增大，skip 跳过的条目也会随之变大，而这个操作是通过 cursor 的迭代器来实现的，对于cpu的消耗会非常明显，当页码非常大时且频繁时，必然爆炸。

### ElasticSearch

从业务的角度来说，`ElasticSearch`不是典型的数据库，它是一个搜索引擎，如果在筛选条件下没有搜索出想要的数据，继续深度分页也不会找到想要的数据，退一步讲，假如我们把`ES`作为数据库来使用进行查询，在进行分页的时候一定会遇到`max_result_window`的限制，看到没，官方都告诉你最大偏移量限制是一万。

查询流程：

1. 如查询第501页，每页10条，客户端发送请求到某节点
2. 此节点将数据广播到各个分片，各分片各自查询前 5010 条数据
3. 查询结果返回至该节点，然后对数据进行整合，取出前 5010 条数据
4. 返回给客户端

由此可以看出为什么要限制偏移量，另外，如果使用 `Search After` 这种滚动式API进行深度跳页查询，也是一样需要每次滚动几千条，可能一共需要滚动上百万，千万条数据，就为了最后的20条数据，效率可想而知。



## 通用解决方案

短时间内快速解决的方案主要是以下几点：

- 必备：对排序字段，筛选条件务必设置好索引
- 核心：利用小范围页码的已知数据，或者滚动加载的已知数据，减少偏移量
- 额外：如果遇到不好处理的情况，也可以获取多余的数据，进行一定的截取，性能影响并不大

### MySQL

原分页SQL：

```sql
# 第一页
SELECT * FROM `year_score` where `year` = 2017 ORDER BY id limit 0, 20;

# 第N页
SELECT * FROM `year_score` where `year` = 2017 ORDER BY id limit (N - 1) * 20, 20; 
```

通过上下文关系，改写为：

```sql
# XXXX 代表已知的数据
SELECT * FROM `year_score` where `year` = 2017 and id > XXXX ORDER BY id limit 20;
```

LIMIT会在满足条件下停止查询，因此该方案的扫描总量会急剧减少，效率提升Max！

### ES

方案和`MySQL`相同，此时我们就可以随用所欲的使用 `FROM-TO` Api，而且不用考虑最大限制的问题。



如果你没有杠过产品经理，又该怎么办呢，没关系，还有一丝丝的机会。

在 [SQL优化](https://juejin.im/post/5ea16dede51d45470b4ffc5b#heading-8) 一文中还提到过`MySQL`深度分页的处理技巧，代码如下：

```sql
# 反例（耗时129.570s）
select * from task_result LIMIT 20000000, 10;

# 正例（耗时5.114s）
SELECT a.* FROM task_result a, (select id from task_result LIMIT 20000000, 10) b where a.id = b.id;

# 说明
# task_result表为生产环境的一个表，总数据量为3400万，id为主键，偏移量达到2000万
```

该方案的核心逻辑即基于`聚簇索引`，在不通过`回表`的情况下，快速拿到指定偏移量数据的主键ID，然后利用`聚簇索引`进行回表查询，此时总量仅为10条，效率很高。

因此我们在处理`MySQL`，`ES`，`MongoDB`时，也可以采用一样的办法：

1. 限制获取的字段，只通过筛选条件，深度分页获取主键ID
2. 通过主键ID定向查询需要的数据

瑕疵：当偏移量非常大时，耗时较长，如文中的 5s