# 一、OS

## 1. 进程与线程的区别

在早期的操作系统中，只有进程，没有线程， 随着技术发展，在执行一些细小任务时，本身无需分配单独资源时，也只能创建进程来执行，但是进程切换开销很大，而且进程间通信共享数据也很麻烦，所以就提出了线程的概念。

一个进程独享一块虚拟内存，线程就是在进程的虚拟内存中分配一套独立的栈和寄存器，CPU操作的是线程的栈帧，所以线程是调度的基本单位，而共享进程的虚拟内存空间，所以进程是资源分配的基本单位。

在linux系统中，实际上没有线程的概念，只用了一个task_struct结构体，进程创建子进程时会指定他和自己使用同一套地址空间和句柄表的资源，用这种方法实现多线程的效果。而在windows系统中，进程对应一个PCB进程控制块，而线程使用TCB记录的



## 2.进程和线程间的通信方式

进程：

- 匿名管道，命名管道（见[进程与线程](http://47.116.70.98:8081/Linux/Linux%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B.html)，观看管道原理详解）
- 消息队列
- 共享内存
- 信号
- socket

线程：**因为同一进程的不同线程共享同一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段，所以线程之间可以方便、快速地共享信息。只需要将数据复制到共享（全局或堆）变量中即可。**不过，要避免出现多个线程试图同时修改同一份信息，通常使用：

- 互斥锁
- 信号量



## 3. 线程、协程的区别

先讲解一下虚拟内存分为内核空间和用户空间，所有的系统操作，都得由用户发起系统中断，转而在内核空间中完成。线程可以说是内核级线程，而协程则是由线程创建，操作系统无法调度，由线程自己调度，自己分配空间，但只能在用户空间中，不能涉及内核空间。



## 4. 常见的进程调度算法

先来先服务，短作业优先，高响应比优先，时间片轮转



## 5. 进程线程的状态

因为线程是CPU调度的基本单位，而在Linux系统中，其实没有线程和进程的概念的区分，所以他们的状态都是：

- 创建，就绪，运行，阻塞，结束
- 创建，就绪，就绪挂起，运行，阻塞，阻塞挂起，结束



## 6. 僵尸进程和孤儿进程

`僵尸进程`（Z僵死状态（zombie））：当一个子进程结束运行（一般是调用exit、运行时发生致命错误或收到终止信号所导致）时，子进程的退出状态（返回值）会回报给操作系统，系统则以SIGCHLD信号将子进程被结束的事件告知父进程，此时子进程的进程控制块（PCB）仍驻留在内存中。一般来说，收到SIGCHLD后，父进程会使用wait系统调用以获取子进程的退出状态，然后内核就可以从内存中释放已结束的子进程的PCB；而如若父进程没有这么做的话，子进程的PCB就会一直驻留在内存中，也即成为僵尸进程

其实，僵尸进程是有危害的。进程的退出状态必须被维持下去，因为它要告诉关心它的进程（父进程），你交给我的任务，我办的怎么样了。可父进程如果一直不读取，那子进程就一直处于Z状态。维护退出状态本身就是要用数据维护，也属于进程基本信息，所以保存在task_struct(PCB)中，换句话说，当一个进程一直处于Z状态，那么它的PCB也就一直都要被维护。因为PCB本身就是一个结构体会占用空间，僵尸进程也就会造成资源浪费，所以我们应该避免僵尸进程的产生

想要解决僵尸进程也很简单，直接找到父进程杀掉，那么僵尸进程将会被init进程接管，并回收

`孤儿进程`：孤儿进程则是指当一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

孤儿进程由于有init进程循环的wait()回收资源，因此并没有什么危害



## 7. 管道的底层实现原理

创建管道会返回两个描述符，管道的读取端描述符 `fd[0]`，另一个是管道的写入端描述符 `fd[1]`

匿名管道是特殊的文件，只存在于内存，不存于文件系统中。也就是内核空间里面的一段缓存，通过父子进程共享文件描述符，来进行管道通信。

而对于命名管道，也就是创建了一个管道文件，只要在进程中读取这个文件，就可以达到通信的目的



## 8. 线程和进程的上下文切换

`同一个进程的线程上下文切换`: 只需要将线程的执行现场保存起来，就是栈帧，指令指针，寄存器等。再把

指令指针，栈指针这些寄存器的值修改为新线程的信息。

`不同进程的线程上下文切换`：如果是不同进程间的切换，就要涉及到进程的切换。首先CPU保存的页表需要切换到进程B，所以进程切换和线程切换的区别是，进程切换会导致地址空间等进程资源发生变化，还会导致TLB缓存失效，代价会更大。**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源**



## 9. 虚拟内存

可以从为什么会有虚拟内存，虚拟内存如何映射到物理内存，一级页表和二级页表的区别，二级页表为什么省空间，线性地址后12位多余字段的作用，虚拟内存的空间分配

详见： [虚拟内存](http://47.116.70.98:8081/Linux/Linux%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98.html)



## 10. 内存泄漏和内存溢出

- 内存溢出**（Out Of Memory）**：申请内存时，没有足够的空间

- 内存泄漏**（Memory Leak）**：申请了内存，但没有释放，导致空间浪费

  - 也就是向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。

  

也就是内存泄漏最终会导致内存溢出



## 11. 页面置换算法

当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

- 最佳页面置换算法（OPT）
  - **置换在「未来」最长时间不访问的页面**
- 先进先出置换算法（FIFO）
  - **选择在内存驻留时间很长的页面进行中置换**
- 最近最久未使用的置换算法（LRU）
  - **选择最长时间没有被访问的页面进行置换**
- 最不常用置换算法（LFU）
  - **选择「访问次数」最少的那个页面，并将其淘汰**



## 12. 用户态内核态切换

线程中发生函数调用就是在线程栈中分配函数调用栈，而虚拟内存分配，文件操作，网络读写等很多功能都是由操作系统来完成的，再向用户程序暴露接口。所以线程免不了要“系统调用”，CPU中会有一个特权标志，用于记录当前程序是执行在用户态还是内核态，只有标记为内核态才可以访问内核空间。如果线程处于用户态，就不能访问内核空间，所以系统调用发生时，就得切换到内核态，使用线程的内核栈，执行内核空间的系统函数

最初系统调用是通过软中断触发的，就是通过指令模拟中断。在OS中，会有一张中断向量表，用来吧各个中断编号映射到相应的处理程序，例如在linux系统中，系统调用中断对应的编号为0x80，对应的系统程序，就是用来派发系统调用的。在硬件层面，CPU有一个中断控制器，负责接收中断信号，切换到内核态，保存用户态执行现场。一部分寄存器的值会通过硬件保存起来，还有一部分通用寄存器的值，会被压入内核栈中。等系统调用结束后，再利用之前保存的信息，恢复线程在用户态的执行现场，继续执行后面的指令，即完成的一次系统调用。

后改为特殊指令触发系统调用，如sysenter，syscall，当cpu执行到这些指令时，就会陷入内核态，从专用的寄存器拿到派发入口的地址，省去了查询中断向量表的过程。



## 13. 软中断和硬中断

- 软中断是执行中断指令产生的，而硬中断是由外设引发的。
- 硬中断的中断号是由中断控制器提供的，软中断的中断号由指令直接指出，无需使用中断控制器。
- 硬中断是可屏蔽的，软中断不可屏蔽。

为了避免由于中断处理程序执行时间过长，而影响正常进程的调度，Linux 将中断处理程序分为上半部和下半部：

- 上半部，对应硬中断，由硬件触发中断，用来快速处理中断；
- 下半部，对应软中断，由内核触发中断，用来异步处理上半部未完成的工作；

软终端有：网络收发、定时、调度、RCU 锁等各种类型,可以通过查看 /proc/softirqs 来观察软中断的累计中断次数情况







# 二、网络/基础

## 1. **OSI七层、五层模型，每一层的作用**

OSI七层模型：

- 物理层：主要定义物理设备标准，它的主要作用是传输比特流，这一层的数据叫做比特。
- 数据链路层：在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧在信道上无差错的传输，并进行各电路上的动作系列。数据链路层在不可靠的物理介质上提供可靠的传输　　
- 网络层
- 传输层
- 会话层
- 表示层
- 应用层

|            | 功能                                                         | 网络设备                                                     | 协议      |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- |
| 应用层     | 直接向用户提供服务，完成用户希望在网络上完成的各种工作       |                                                              | HTTP, FTP |
| 表示层     | 处理用户信息的表示问题，如编码、数据格式转换和加密解密等     |                                                              | Telnet    |
| 会话层     | 组织和协调两个会话进程之间的通信 ，并对数据交换进行管理      |                                                              | DNS       |
| 传输层     | 向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输，同时向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。 |                                                              | TCP、UDP  |
| 网络层     | 在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送 | 路由器、三层交换机                                           | IP、ARP   |
| 数据链路层 | 在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧在信道上无差错的传输，并进行各电路上的动作系列。数据链路层在不可靠的物理介质上提供可靠的传输 | 网桥（Linux虚拟网桥）、交换机)（二层交换机）、网卡（其实网卡是一半工作在物理层、一半工作在数据链路层） | PPP       |
| 物理层     | 主要定义物理设备标准，它的主要作用是传输比特流，这一层的数据叫做比特 | 中继器、集线器                                               | IEEE      |



## 2. 集线器、交换机、三层交换机、路由器

- 集线器：工作在osi第一层机物理层，传输的单位是比特，会以广播的形式传输
- (二层)交换机：具有MAC地址转发表，会指定端口进行传输
- 三层交换机：是利用MAC地址（物理地址）来确定转发数据的目的地址，主要用于局域网之间的连接
- 路由器：利用IP地址（网络地址）来确定数据转发的地址，主要是将多个局域网连接到广域网，除此之外，路由器还比三层交换机多防火墙等功能



## 3. 浏览器上输入地址后的整个请求过程

- 对 `URL` 进行解析之后，浏览器确定了 Web 服务器和文件名，然后根据这些信息来生成 HTTP 请求消息
- DNS解析，**查询服务器域名对于的 IP 地址**（本地->根域名服务器->com顶级域名服务器->server.com区域dns服务器->返回本地dns->本地dns告诉客户端）
- 建立TCP连接
- 发起http请求
- 服务器处理请求，返回处理结果（状态码）
- 关闭TCP
- 浏览器解析html



# 三、网络/传输层

## 1. Tcp与Udp区别

TCP：面向连接的可靠传输，需要三次握手来建立连接，提供确认、窗口、重传、拥塞控制等机制，慢

UDP：面向无连接的不可靠传输，快，存在丢包问题，适用于网络通讯质量要求不高的时候



## 2. Tcp三次握手四次挥手及对应的状态

### 三次握手

服务端首先是Listen状态，客户端是close状态。

1. 客户端把syn置1，随机初始化序列号，发送给服务端，随后客户端进入发送状态
2. 服务端收到消息后，将自己syc、ack置1，初始化自己的序列号，应答号设置为客户端序列号+1，发送给客户端，自己进入rcvd状态
3. 客户端收到消息后，在给服务端发送一个应答报文，确认应答号为服务端序列号+1，进入established状态
4. 服务端收到报文后，进入established确认状态，连接成功



### 四次挥手

1. 假如客户端想关闭连接，则把自己的FIN标志置为1，发送FIN报文，之后会进入fin_wail1状态
2. 服务端收到报文，回复ack报文，进入close_wait状态，继续处理没处理完的任务
3. 处理完成后，发送Fin报文,进入last_ack状态
4. 客户端收到fin报文后，进入time_wait状态，并给服务端发送ack报文，服务端进入close状态
5. 客户端经过2msl后，进入close状态



## 3. 为什么要三次握手，四次挥手

### 三次握手

为了保证可靠的信道传输

- 避免历史连接，如果客户端发送了很多的syn报文，旧的syc报文先到了服务端，那么服务端就会发送ack报文回复，客户端收到后，会回复强制停止报文RST，如果是两次握手，那么此时就建立连接成功了
- 为了同步两边的序列号，至少要三次握手，才能确保双方的初始序列号能被可靠的同步。
- 避免资源的浪费，两次握手的话，服务端不知道自己的ack报文对方有没有收到，所以收到syn，就要建立连接，如果客户端有大量syc阻塞的无用请求，服务端会造成浪费



### 四次挥手

服务端需要等待完成数据的发送和处理，所以ACK和FIN报文需要分开发送，从而比三次握手多了一次



## 4. TIME_WAIT

### 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

- 防止具有相同「四元组」的「旧」数据包被收到；
- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

也就是如果客服端的ack报文，对方没有收到，服务端会重传fin报文，如果这时已经关闭，那么就会造成服务端资源的浪费，所以要等待，确认对方收到了ack报文，在关闭



### 为什么 是 2MSL？

MSL是指最大报文生存时间，

- 保证四次挥手中主动关闭方最后的 ACK 报文能最终到达对端
- 保证对端没有收到 ACK 那么进行重传的 FIN 报文能够到达



## 5. 粘包拆包

拆包：

1. 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
2. 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。



粘包：

1. 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
2. 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。



>解决办法

 1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。

 2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。

 3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。



## 6. TCP重传

- 超时重传，超时重传时间应略大于报文往返时间
- 快速重传：发送方收到三次同样的ACK报文，就会重传
- SACK重传：接收方有一个接收缓冲区，可以把信息放入缓冲区中，发送方重传只需要发送丢失的数据段



## 7. 滑动窗口、流量控制

为了能保证**无需等待确认应答，而可以继续发送数据**，引入了滑动窗口的概念，窗口大小由接收方确认。

- 发送方窗口：
  - 指向窗口的开始，也就是已发送但确认的窗口的第一个字节
  - 执行未发送但可以发送的第一个字节
  - 窗口大小
- 接收方窗口：
  - 执行期望下一个发送来的序列号
  - 窗口大小



发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。TCP的流量控制用滑动窗口机制来实现。



如果进程没有及时读取缓存，就会影响窗口大小的变化。

**为了防止丢包，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间在减少缓存，这样就可以避免了丢包情况。**



## 8. 拥塞控制

流量控制是控制接收方的读取能力，但是并没有考虑当前的网络状况，如果当前网络较差，会造成数据包的延时、丢失等，tcp就会一直重传，导致网络负担更重。于是，就有了拥塞控制



>**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

发送窗口的值，此时等于 min(接收窗口，拥塞窗口)



### 拥塞控制算法

1. 慢启动：拥塞窗口初始为1，当发送方每收到一个ack，拥塞窗口的大小就会+1，直到达到慢启动门限，指数级增长

2. 拥塞避免算法：每个ack增加 1/拥塞窗口的大小，也就是假如拥塞窗口为8，需要8个ack，就会增加为9。线性增长

3. 拥塞发生：

   超时重传：就会把慢启动门限设置为拥塞窗口/2，再拥塞窗口设置为1，接着开启慢启动。

   快速重传：拥塞窗口设置为原来的一般，并把慢启动门限更新为此时的拥塞窗口，进入快速恢复算法

4. 快速恢复：快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

   - 拥塞窗口+3 （收到了三个ack）
   - 如果再收到重复的 ACK，那么 cwnd 增加 1
   - 如果收到新数据的 ACK 后，设置 拥塞窗口 为 慢启动门限，接着就进入了拥塞避免算法

# 四、网络/Http

## 1. HTTP常见的状态码

- *1xx*：`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

- *2xx*：`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。
  - 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
  - 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据
  - 「**206 Partial Content**」是应用于 HTTP 分块下载或断电续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

- *3xx*：`3xx` 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。
  - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
  - 「**302 Moved Permanently**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
    - 301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
  - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。
- *4xx*：`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。
  - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
  - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
  - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
- *5xx*：`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码
  - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
  - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
  - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
  - 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。



## 2. GET 与 POST

- `Get` 方法的含义是请求**从服务器获取资源**，这个资源可以是静态的文本、页面、图片视频等。
- 而`POST` 方法则是相反操作，它向 `URI` 指定的资源提交数据，数据就放在报文的 body 里。



> GET 和 POST 方法都是安全和幂等的吗？

先说明下安全和幂等的概念：

- 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。



那么很明显 **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

**POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。



## 3. Http请求、响应的报文格式

### 3.1 请求报文

请求行、请求头部、空行和报文主体

![img](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220228101211.jpeg)



### 3.2 响应报文

状态行、响应头部、空行和报文主体

![img](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220228101305.jpeg)



## 4. HTTP常见字段有哪些

- *Host*：客户端发送请求时，用来指定服务器的域名。
- *Content-Length 字段*：表明本次回应的数据长度。
- *Connection 字段*：`Connection` 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。Connection: keep-alive
- *Content-Type 字段*:用于服务器回应时，告诉客户端，本次数据是什么格式。
- *Content-Encoding 字段*:说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式

## 5. HTTP1.0和1.1、2

- HTTP1.0：每次连接都要三次握手

- HTTP1.1：

  - 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
  - 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
  - 但存在一些问题：
    - 请求头未压缩，发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
    - 服务器按顺序响应，容易阻塞；
    - 没有请求优先级控制；
    - 请求只能从客户端开始，服务器只能被动响应。

- HTTP2：

  - **压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

  - HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式。****增加了数据传输的效率**。

  - HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

  - HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。

  - HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

  - 存在的问题：

    - HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。

      所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

- HTTP3:

  - **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

## 6. HTTPS

HTTP 由于是明文传输，所以安全上存在以下三个风险：

- **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
- **篡改风险**，比如强制入垃圾广告，视觉污染，用户眼容易瞎。
- **冒充风险**，比如冒充淘宝网站，用户钱容易没。

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议。可以很好的解决了上述的风险



> HTTPS 是如何解决上面的三个风险的？

- **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

![图片](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220227155135.jpeg)

SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。



**（1）如何保证公钥不被篡改？**

> 解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。

**（2）公钥加密计算量太大，如何减少耗用的时间？**

> 解决方法：每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。

因此，SSL/TLS协议的基本过程是这样的：

> （1） 客户端向服务器端索要并验证公钥。
>
> （2） 双方协商生成"对话密钥"。
>
> （3） 双方采用"对话密钥"进行加密通信。

上面过程的前两步，又称为"握手阶段"（handshake）。



## 7. Htpp和WebSocket

`HTTP`是单向的，客户端发送请求，服务器发送响应。举例来说，当客户端向服务器发送请求时，该请求以`HTTP`或`HTTPS`的形式发送，在接收到请求后，服务器会将响应发送给客户端。每个请求都与一个对应的响应相关联，在发送响应后客户端与服务器的连接会被关闭。每个`HTTP`或`HTTPS`请求每次都会新建与服务器的连接，并且在获得响应后，连接将自行终止。 `HTTP`是在`TCP`之上运行的无状态协议，`TCP`是一种面向连接的协议，它使用三向握手方法保证数据包传输的传递并重新传输丢失的数据包。



`WebSocket`是双向的，在客户端-服务器通信的场景中使用的全双工协议，与`HTTP`不同，它以`ws://`或`wss://`开头。它是一个有状态协议，这意味着客户端和服务器之间的连接将保持活动状态，直到被任何一方（客户端或服务器）终止。在通过客户端和服务器中的任何一方关闭连接之后，连接将从两端终止。

# 五、Mysql

## 1. B- 树与 B+ 树的区别

- #### 单点查询

B+ 树只有叶子节点才会存放数据，B树所有节点都存放数据，所以B-树在最好的情况下可能达到O(1)，但波动较大。B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少

- #### 插入和删除效率

B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快。B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形。

- #### 范围查询

B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助。B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树



## 2. 为什么用B+树，不用二叉树、B树和红黑树

要设计一个 MySQL 的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I/0 的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I/0 的操作次数内完成。



二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。

为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。

而树的高度决定于磁盘  I/O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I/O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。



B 树和 B+ 都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

但是 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：

- B+树非叶子结点不存放数据，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。

- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。



而红黑树基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。



## 3. 事务的特性

ACID：原子性，一致性，隔离性，持久性

- 原子性、持久性：通过 redo log （重做日志）来保证的
- 一致性：通过 undo log（回滚日志） 来保证的
- 隔离性：通过 MVCC（多版本并发控制） 或锁机制来保证的



## 4. 执行事务会引发的问题

- 脏读：**如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。**
- 不可重复度：**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。**
- 幻读：**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。**

## 5. 事务的隔离级别、如何实现

- **读未提交（\*read uncommitted\*）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（\*read committed\*）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（\*repeatable read\*）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（\*serializable\* ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；
- ![image-20220221131841259](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220221131841.png)



这四种隔离级别具体是如何实现的呢？

### 5.1 读未提交

对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；

### 5.2 串行化

对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；

### 5.3. 可重复读

「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。

Read View的四个字段：

- creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**
- m_ids ：指的是创建 Read View 时当前数据库中**活跃且未提交的事务的事务 id 列表**，注意是一个列表。
- min_trx_id ：指的是创建 Read View 时当前数据库中**活跃且未提交的事务中最小事务的事务 id**，也就是 m_ids 的最小值。
- max_trx_id ：创建 Read View 时当前数据库中应该给下一个事务的 id 值**；



同时我们还需要了解聚族索引记录中的两个隐藏列，对于使用 InnoDB 存储引擎的数据库表，它的聚族索引记录中都包含下面两个隐藏列：

- trx_id，当一个事务对某条聚族索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- roll_pointer，每次对某条聚族索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。



「可重复读」隔离级别就是在启动时创建了 Read View，然后在事务期间读取数据的时候，在找到数据后，先会将该记录的 trx_id 和该事务的 Read View 里的字段做个比较：

- 如果记录的 trx_id 比该事务的 Read View 中的 creator_trx_id 要小，且不在 m_ids 列表里，这意味着这条记录的事务早就在该事务前提交过了，所以该记录对该事务可见；
- 如果记录的 trx_id 比该事务的 Read View 中的 creator_trx_id 要大，且在 m_ids 列表里，这意味着该事务读到的是和自己同时启动的另外一个事务修改的数据，这时就不应该读取这条记录，而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 等于或者小于该事务 id 的第一条记录。

**这种通过记录的版本链来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。**



### 5.4 读已提交

对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View **来实现的，它们的区别在于创建 Read View 的时机不同：

- 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
- 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。



## 6. Mysql有哪些锁

### 共享锁与排他锁

InnoDB 实现了标准的行级锁，包括两种：共享锁（简称 s 锁）、排它锁（简称 x 锁）。

- 共享锁（S锁）：允许持锁事务读取一行。
- 排他锁（X锁）：允许持锁事务更新或者删除一行。



### 意向锁

- 意向共享锁( IS 锁)：事务想要获得一张表中某几行的共享锁
- 意向排他锁( IX 锁)：事务想要获得一张表中某几行的排他锁



### 记录锁（Record Locks）

- 记录锁是最简单的行锁，**仅仅锁住一行**。如： `SELECT c1 FROM t WHERE c1=10 FOR UPDATE`
- 记录锁**永远都是加在索引上**的，即使一个表没有索引，InnoDB也会隐式的创建一个索引，并使用这个索引实施记录锁。
- 会阻塞其他事务对其插入、更新、删除



### 间隙锁（Gap Locks）

- 间隙锁是一种加在两个索引之间的锁，或者加在第一个索引之前，或最后一个索引之后的间隙。
- 使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。
- 间隙锁只阻止其他事务插入到间隙中，他们不阻止其他事务在同一个间隙上获得间隙锁，所以 gap x lock 和 gap s lock 有相同的作用。



### Next-Key Locks

- Next-key锁是记录锁和间隙锁的组合，它指的是加在某条记录以及这条记录前面间隙上的锁。

## 7. Mysql死锁

**Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁**，它是记录锁和间隙锁的组合。

- Record Loc，记录锁，锁的是记录本身；
- Gap Lock，间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。



next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。



事务 A 和事务 B 在执行完后 `select ... for update` 语句后都持有范围为`(1006,+∞）`的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。

![image-20220221183627514](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220221183627.png)

## 8. 聚簇索引和非聚簇索引

- 聚集索引：聚集索引就是以主键创建的索引，在叶子节点存储的是表中的数据。
- 非聚集索引：非聚集索引就是以非主键创建的索引，在叶子节点存储的是主键和索引列。



InnoDB 会使用聚簇索索引来保存数据，而非聚簇索引的目的仅仅是加快查询速度

- 聚簇索引是唯一的，一个 InnoDB 表只有一个聚簇索引，而且一定会有一个聚簇索引，如果不存在，Innodb 存储引擎会自动添加一个
- 非聚簇所以可以有多个，而且只能由用户自己添加，InnoDB 默认并不会创建任何非聚簇索引。



>什么是回表？通过非聚簇索引拿到主键再回到主键索引查询的过程，就叫做**「回表」**



## 9. 索引失效

- 对索引使用左模糊匹配：**因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。**

- 对索引使用函数

- 对索引隐式类型转换
  - **MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较**
  - **也就是对索引使用了函数**
- 联合索引非最左匹配
  - 原因是，在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引。.
- WHERE 子句中的 OR
  - 因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描




## 10. Mysql慢查询优化

### 10.1  正确使用索引

- 正确设计索引
- 避免sql全表扫描，sql一定要走索引
- 避免索引失效
  - or
  - 对索引使用左模糊
  - 对索引使用函数
  - 联合索引非最左匹配

### 10.3 优化LIMIT分页

  对于下面的查询：

    select id,title from collect limit 90000,10;
  该语句存在的最大问题在于limit M,N中偏移量M太大（我们暂不考虑筛选字段上要不要添加索引的影响），导致每次查询都要先从整个表中找到满足条件 的前M条记录，之后舍弃这M条记录并从第M+1条记录开始再依次找到N条满足条件的记录。如果表非常大，且筛选字段没有合适的索引，且M特别大那么这样的代价是非常高的。 

可以改为：

```
select id,title from collect where id>=(select id from collect order by id limit 90000,1) limit 10;
```

原理：先查询出90000条数据对应的主键id的值，然后直接通过该id的值直接查询该id后面的数据。

```
SELECT * FROM t_topic WHERE id BETWEEN 90000 AND 90010;  
```

使用 between and 语句分页效率快N倍



### 10.2 分表

1，采用分表技术（大表分小表）

a)垂直分表：将部分字段分离出来，设计成分表，根据主表的主键关联
b)水平分表：将相同字段表中的记录按照某种Hash算法进行拆分多个分表



### 10.3 服务器方面：

1,采用内存缓存系统，减少数据库读取操作
2,采用主从数据库设计，分离数据库的读写压力



## 11. 三大范式

- 第一范式：每个属性不能分解
- 第二范式：每个属性都依赖主属性
- 第三范式：不存在传递依赖





# 六、Redis

## 1. 缓存雪崩

发生缓存雪崩有两个原因：

- 大量数据同时过期；
- Redis 故障宕机；

> 大量数据同时过期

*1. 均匀设置过期时间*

*2. 互斥锁*：当业务线程在处理用户请求时，**如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**

*3. 双 key 策略*

*4. 后台更新缓存*：业务线程不再负责更新缓存，缓存也不设置有效期，而是**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。



> Redis 故障宕机

*1. 服务熔断或请求限流机制*：**暂停业务应用对缓存服务的访问，直接返回错误**,为了减少对业务的影响，我们可以启用**请求限流**机制，**只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务**

*2. 构建 Redis 缓存高可靠集群*：主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务



## 2. 缓存击穿

如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是**缓存击穿**的问题。



可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。

- 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
- 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；



## 3. 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。



缓存穿透的发生一般有这两种情况：

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；



第一种方案，非法请求的限制

第二种方案，缓存空值或者默认值

*第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。*



## 4. RDB和AOF的区别与优劣势

### AOF 日志 

Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，然后重启 Redis 的时候，先去读取这个文件里的命令，并且执行它



劣势：

- 第一个风险，执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有**丢失的风险**。
- 第二个风险，前面说道，由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是**可能会给「下一个」命令带来阻塞风险**。



### RDB 快照

RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。

优点：在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。

缺点：在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。



## 5. Redis缓存与如何保证数据一致性问题

- **先更新数据库 ，再删除缓存**
  - **因为缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。
  - 但是如果删除缓存失败，就会等到缓存到期之后才更新



- 先删除缓存，再更新数据库

![图片](https://gitee.com/lzw657434763/pictures/raw/master/Blog/20220224170416.png)

对于这种情况，可以采用**延迟双删**的模式

```
#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
```



## 6. redis数据结构

- string（字符串）:共享session、分布式锁，计数器、限流。
- List（列表）: 消息队列，文章列表
- Hash（哈希）:缓存用户信息
- Set（集合）:用户标签,生成随机数抽奖、社交需求
-  Zset（有序集合）:排行榜，社交需求（如用户点赞）

## 7. redis如何实现分布式锁

使用Redis的 SETNX 命令可以实现分布式锁

SETNX：将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。SETNX 是SET if Not [eXists](https://so.csdn.net/so/search?q=eXists&spm=1001.2101.3001.7020)的简写。

多个进程执行以下Redis命令：

```
SETNX lock.foo <current Unix time + lock timeout + 1>
```

如果 SETNX 返回1，说明该进程获得锁，SETNX将键 lock.foo 的值设置为锁的超时时间（当前时间 + 锁的有效时间）。
如果 SETNX 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。

## 8. Redis过期策略

- 定时删除
  - 含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除
  - 优点：保证内存被尽快释放
  - 缺点：
    - 若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key
    - 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重
    - 没人用
- 惰性删除
  - 含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。
  - 优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）
  - 缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）
- 定期删除
  - 含义：每隔一段时间执行一次删除过期key操作
  - 优点：
    - 通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点
    - 定期删除过期key--处理"惰性删除"的缺点
  - 缺点
    - 在内存友好方面，不如"定时删除"
    - 在CPU时间友好方面，不如"惰性删除"
  - 难点
    - 合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了）



redis采用惰性删除+定期删除



## 9. redis为什么这么快

- 基于内存实现
- 高效的数据结构
- 合理的线程模型
  - redis单线程指的是网络IO和键值对读写是由一个线程来完成的，但redis的其他功能，例如持久化，异步删除等，都是由额外的线程
  - 单线程模型，避免CPU不必要的上下文切换和竞争锁的消耗
  - IO多路复用：一种同步IO模型，实现了一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能通知应用程序进行相应的读写操作；而没有文件句柄就绪时，就会阻塞应用程序，交出cpu
- 虚拟内存机制：实现冷热数据分离，热数据保存在内存中，冷数据保存到磁盘，避免内存不足

